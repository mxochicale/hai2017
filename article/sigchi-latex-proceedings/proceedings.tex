\documentclass{sigchi}

% Use this section to set the ACM copyright statement (e.g. for
% preprints).  Consult the conference website for the camera-ready
% copyright statement.

% Copyright
\CopyrightYear{2017}
%\setcopyright{acmcopyright}
\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}
% DOI
\doi{http://dx.doi.org/10.475/123_4}
% ISBN
\isbn{123-4567-24-567/08/06}
%Conference
\conferenceinfo{HAI'17,}{October 17--20, 2016, Bielefeld, Germany}
%Price
\acmPrice{\$15.00}

% Use this command to override the default ACM copyright statement
% (e.g. for preprints).  Consult the conference website for the
% camera-ready copyright statement.

%% HOW TO OVERRIDE THE DEFAULT COPYRIGHT STRIP --
%% Please note you need to make sure the copy for your specific
%% license is used here!
% \toappear{
% Permission to make digital or hard copies of all or part of this work
% for personal or classroom use is granted without fee provided that
% copies are not made or distributed for profit or commercial advantage
% and that copies bear this notice and the full citation on the first
% page. Copyrights for components of this work owned by others than ACM
% must be honored. Abstracting with credit is permitted. To copy
% otherwise, or republish, to post on servers or to redistribute to
% lists, requires prior specific permission and/or a fee. Request
% permissions from \href{mailto:Permissions@acm.org}{Permissions@acm.org}. \\
% \emph{CHI '16},  May 07--12, 2016, San Jose, CA, USA \\
% ACM xxx-x-xxxx-xxxx-x/xx/xx\ldots \$15.00 \\
% DOI: \url{http://dx.doi.org/xx.xxxx/xxxxxxx.xxxxxxx}
% }

% Arabic page numbers for submission.  Remove this line to eliminate
% page numbers for the camera ready copy
% \pagenumbering{arabic}

% Load basic packages
\usepackage{balance}       % to better equalize the last page
\usepackage{graphics}      % for EPS, load graphicx instead
\usepackage[T1]{fontenc}   % for umlauts and other diaeresis
\usepackage{txfonts}
\usepackage{mathptmx}
\usepackage[pdflang={en-US},pdftex]{hyperref}
\usepackage{color}
\usepackage{booktabs}
\usepackage{textcomp}

% Some optional stuff you might like/need.
\usepackage{microtype}        % Improved Tracking and Kerning
% \usepackage[all]{hypcap}    % Fixes bug in hyperref caption linking
\usepackage{ccicons}          % Cite your images correctly!
% \usepackage[utf8]{inputenc} % for a UTF8 editor only

% If you want to use todo notes, marginpars etc. during creation of
% your draft document, you have to enable the "chi_draft" option for
% the document class. To do this, change the very first line to:
% "\documentclass[chi_draft]{sigchi}". You can then place todo notes
% by using the "\todo{...}"  command. Make sure to disable the draft
% option again before submitting your final document.
\usepackage{todonotes}

% Paper metadata (use plain text, for PDF inclusion and later
% re-using, if desired).  Use \emtpyauthor when submitting for review
% so you remain anonymous.
% \def\plaintitle{SIGCHI Conference Proceedings Format}
\def\plaintitle{Towards the Analysis of Movement Variability in Human-Humanoid Imitation Activities}

\def\plainauthor{First Author, Second Author, Third Author,
  Fourth Author, Fifth Author, Sixth Author}
\def\emptyauthor{}
\def\plainkeywords{Authors' choice; of terms; separated; by
  semicolons; include commas, within terms only; required.}
\def\plaingeneralterms{Documentation, Standardization}

% llt: Define a global style for URLs, rather that the default one
\makeatletter
\def\url@leostyle{%
  \@ifundefined{selectfont}{
    \def\UrlFont{\sf}
  }{
    \def\UrlFont{\small\bf\ttfamily}
  }}
\makeatother
\urlstyle{leo}

% To make various LaTeX processors do the right thing with page size.
\def\pprw{8.5in}
\def\pprh{11in}
\special{papersize=\pprw,\pprh}
\setlength{\paperwidth}{\pprw}
\setlength{\paperheight}{\pprh}
\setlength{\pdfpagewidth}{\pprw}
\setlength{\pdfpageheight}{\pprh}

% Make sure hyperref comes last of your loaded packages, to give it a
% fighting chance of not being over-written, since its job is to
% redefine many LaTeX commands.
\definecolor{linkColor}{RGB}{6,125,233}
\hypersetup{%
  pdftitle={\plaintitle},
% Use \plainauthor for final version.
%  pdfauthor={\plainauthor},
  pdfauthor={\emptyauthor},
  pdfkeywords={\plainkeywords},
  pdfdisplaydoctitle=true, % For Accessibility
  bookmarksnumbered,
  pdfstartview={FitH},
  colorlinks,
  citecolor=black,
  filecolor=black,
  linkcolor=black,
  urlcolor=linkColor,
  breaklinks=true,
  hypertexnames=false
}

% create a shortcut to typeset table headings
% \newcommand\tabhead[1]{\small\textbf{#1}}

% End of preamble. Here it comes the document.
\begin{document}

\title{\plaintitle}

\numberofauthors{3}
\author{%
  \alignauthor{Leave Authors Anonymous\\
    \affaddr{for Submission}\\
    \affaddr{City, Country}\\
    \email{e-mail address}}\\
  \alignauthor{Leave Authors Anonymous\\
    \affaddr{for Submission}\\
    \affaddr{City, Country}\\
    \email{e-mail address}}\\
  \alignauthor{Leave Authors Anonymous\\
    \affaddr{for Submission}\\
    \affaddr{City, Country}\\
    \email{e-mail address}}\\
}

\maketitle

\begin{abstract}
  ...
\end{abstract}

\category{I.2.9.}{Robotics}{Sensors}
\category{G.3.}{PROBABILITY AND STATISTICS}{Time series analysis}
% \category{I.5.4.}{Applications}{Signal Progessing}

% \keywords{\plainkeywords}
\keywords{Human-Robot Interaction; Human-Humanoid Imitation;
Wearable Inertial Sensors; State Space Reconstruction}


\section{Introduction}

Movement variability is an inherent feature within a person and between persons
\cite{newell1993variability}. Recently, Herzfeld et al. \cite{Herzfeld2014}
conducted experiments to state that movement variability is not only noise but a
source of movement exploration which at certaing point of the movement performance
such variability is a source of movement explotation.
With this in mind, we have found that there is little research in the area of
human-robot interaction that is focused on the quantification of movemennt variablity.


%
% Blake et al. \cite{Blake2007} reviewed studies of perception of human motion
% in which is stated that
%   % that one contribution to the percpetion of human motion is
% % motor experience
% the ability of people to perceive the actions of other people
% is based on acumulated experiences of planning and executing self-produced
% activites.
% %% REF: MOTORIC CONTRIBUTIONS TO PERCEPTION OF HUMAN MOTION \cite{Blake2007}
%



% Understading the perceptual, motoric, affective and neural mechanisms
% of perception of human motion has been
% which is the ability of


% ...I AM READING THESE PAPERS TO COMPLETE THE INTRODUCTION:
% Perception of Human Motion \cite{Blake2007}.
% Pigeons and humans use action and pose information to categorize complex human behaviors
% \cite{Qadri201716}. The visual perception of velocity \cite{Brown1931}.
% Implied Dynamics Biases the Visual Perception of Velocity \cite{LaScaleia2014}.
% Attention to body-parts varies with visual preference and verb--effector associations \cite{Boyer2017}.
% Comparing Biological Motion Perception in Two Distinct Human Societies \cite{Pica2011}
% % Motion perception: from phi to omega \cite{Rose967}

\section{METHOD}

\subsection{State Space Reconstruction}
In this work we follow the notation employed in \cite{Uzal2011}.
The purpose of time-delay embedding, also known as Takens's Theorem,
is to reconstruct the topological properties of an unknown $M-$dimensional
state space $s(t)$ from a $1-$dimensional measurement $x(t)$ in order to
reconstruct an $N-$dimensional embedding space (Figure \ref{fig:takens_theorem}).
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[!htb]
\centering
\includegraphics[width=0.45\textwidth]{figures/reconstructed_state_space/fig}
\caption[PA]{A. $M-$dimensional state space $s(t)$; B. $1-$dimensional measurament
time series $x(t)$; and  C. $N-$dimensional reconstructed state space $v(t)$ where $M \geq N$
\cite{QuintanaDuque2012}.}
\label{fig:takens_theorem}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The time-delay embedding assumes that the time series is a sequence $x(t)=h(s(t))$,
where $h: S \rightarrow \mathbb{R}^M$ is a measurement function on the unknown
dynamical system, being $x(t)$ observable.
Thus, the time delay reconstruction in $m$ dimensions with a time delay
$\tau$ is defined as: $\overline{x}(t) = (x(t), x(t-\tau),...,x(t-(m-1)\tau))$.
Then a further transformation is considered in order to reduce
the dimensionality of the $m-$dimensional reconstructed state space.
For this work, we assume that the signal, $x(t)$, is produced by some time-varying
system which is the time series produced by the linear acceleration of the
inertial sensors attached to both the person and the humanoid robot.
The assumption that the source of the signal exhibits systematic variability
within and between persons leads to the assumption that this signal should,
over some time period, exhibit a repeated pattern between and within persons.
What we do not know is how realiable the quantification methods for movement
variability are and how to establish levels of imitation with a given
movement variability.



\subsection{Determining the embedding parameters ($m$ and $\tau$)}
Although Takens's Theorem has been used extensively in gait
recognition and walking, running and cycling activities,
some problems are still remaining to be solved.
Sama et al. \cite{Sama2013} estimated that the minimal embedded
dimension ($m_{min}$) with False Nearest Neighbours (FNN) method.
However, Cao \cite{Cao1997} pointed out that FNN algorithm
introduces two parameters ($R_{tol}$ and $A_{tol}$) that lead
to different results when distinguishing random series from deterministic series.
Additionally, Sama et al. \cite{Sama2013} states that the minimal embedding
parameters largely depend on the structure (amplitude, frequency, nonlinearity)
of the time series. Thus, there is still research to be done to find
optimus values of the minimal dimension parameters ($m_{min}$ and $\tau_{min}$)
to reconstruct the state space.

% \newpage
\subsection{$E1(d)$ and $E2(d)$ values}
In this work, we follow the Cao's method \cite{Cao1997} to compute the minimal
embedding dimension. Cao's method is based on the mean values of $E1(d)$ and $E2(d)$
where $d$ is the range of evaluation for the embedding dimension.
Therefore, $E1(d)$ is used to obtain the minimal dimension $m_{min}$
where the values of $E1(d)$ stop changing when $d$ comes from an attractor.
$E2(d)$ values are used to distinguish deterministic signals from random signals
in which case the $E2(d)$ values will be approximately equal to 1 for any $d$.
Cao's method is a modified version of the FNN method, and $E1(d)$ and $E2(d)$
values are only dependant on $m$ and $\tau$ .


\section{Experiment Design}

\subsection{Head Pose Estimation}

Estimating head pose in human-robot interactions is an active area of research
% where remain
because of challenges like real-time tracking, the use of less invasive equipment
or the preparation of calibration techniques. However, Lemaignan et al. proposed a head pose estimator
using a monococular RGB webcam which is able to track a head with rotations up
to $\pm$40$^{\circ}$ horizontally and $\pm$30$^{\circ}$ vertically \cite{Lemaignan2016}.
Much recently, OpenFace, a fully open source real-time facial behavior analysis,
provides state-of-the-art performance in facial landmark motion,
head pose (orientation and motion), facial expressions, and eye gaze.
Additionally, OpenFace can operate with a simple webcam in real-time
\cite{Baltrusaitis2016}.

% Perceiving Gaze Cues with a NAO Robot \cite{Mwangi2016}


\section{Experiment}


\subsection{Hyphothesis}
In our previous experiments of a face-to-face human-humanoid imitation
activity \cite{XXX2017} where we proposed metrics to quantify the level of
imitation for upper arm movements, we also observed (by eye) that efects
like boredoom, fatigue or level of engagment might also be a factor that
influence the way each vary beetween persons and within person.
With this in mind, we hyphothesised that not only inertial sensors attached
to the body can provide information about movement variability
but also the head pose estimation which, we believe, will lead us to get
better understanding movement variability and therefore create more
realiable metrics to measure such variability.

\subsection{Participants and Procedure}
In this experiment, we only collected data for eigth male right-handed healthy
participant  (age 22+-1) and ten  female (age 25 +-1).
Besides the inertial sensors attached to both the participant and the robot,
we use the head pose estimation via webcam in order to test our previous hyphothesis.
For this, we designed an experiment where the user(s) imitate NAO robot' arm
movements at a constant speed of 30 frames per seconds.
Such experiment were performed for ten times by the same participant
in order to test the factor of fatigue or boredoom (Figure~\ref{fig:exp}A ).

We use OpenFace \cite{Baltrusaitis2016} to measure the head pose which
 let us hyphothesis that the participant is engagaed
when he/she stared the robots within certain range of movements.


\begin{figure}[!htb]
\centering
\includegraphics[width=0.45\textwidth]{figures/experiment/fig_w619h233}
\caption[PA]{A. Experimental setup: face-to-face imitation with NAO humanoid robot;
B. Head pose estimation with OpenFace \cite{Baltrusaitis2016}
}
\label{fig:exp}
\end{figure}


\subsection{Head Pose Estimation}



\subsection{Accelerometer}
In this work the sequence $x(t)$ is the raw data collected from an (IMU)
for triaxial data for accelerometer ($a_{ \{ x,y,z \} }$),
gyroscope ($g_{ \{ x,y,z \} }$) and magnetometer($m_{ \{ x,y,z \} }$) sensors.
Then, for instance, the time-series $a_x$ with a length of
$N$ samples is used to obtain the Time-delay embedded matrix,
$\boldsymbol{E} a_{x}$, with $m$ rows and $N-(m-1)\tau$ columns.
Finally, the PCA algorithm is applied so as to obtain via eigenvalues
($\lambda_1,\ldots,\lambda_m$), eigenvectors ($v_1,\ldots,v_m$) and
the principal components
($PC_1,\ldots,PC_m$) of the time-delay embedded phase space.




\section{Results}

In Figure~\ref{fig:pose}, we can observe that particpant 04, 08 and 17
present an oscillation in the head which is an unpected behaviour since
NAO was static.
\begin{figure}[!htb]
\centering
\includegraphics[width=0.45\textwidth]{figures/results/Tx}
\caption[PA]{Head Pose Estimation in the Tx axis for 18 participants}
\label{fig:pose}
\end{figure}


* I am analising the data for the previos time-series as well as the
data from the IMUS for the robot and the persons.



\section{Conclusion}

In future experiments, there are three areas that we intend to investigate:
(a) provide further understanding of human movement variablity
(b) perform experiments of interaction with two-humans to one-humanoid and
 three-humans to one-humanoid interactions.
(c) exploration of complex movements which can be performed by both persons and NAO;
(d) data collection from a wider range of individuals (differing gender, age and state of health)
 and from additional inertial sensors attached to the body.






\section{Acknowledgments}

XXX gratefully acknowledges XXX for funding his doctoral studies at
University of XXX. Special thanks is also extended to XXX from XXX at
University of XXX for XXX
acute critics and suitable comments that are helping the work to give a better
shape to the scientific value of knowledge of my research endevours.


% Balancing columns in a ref list is a bit of a pain because you
% either use a hack like flushend or balance, or manually insert
% a column break.  http://www.tex.ac.uk/cgi-bin/texfaq2html?label=balance
% multicols doesn't work because we're already in two-column mode,
% and flushend isn't awesome, so I choose balance.  See this
% for more info: http://cs.brown.edu/system/software/latex/doc/balance.pdf
%
% Note that in a perfect world balance wants to be in the first
% column of the last page.
%
% If balance doesn't work for you, you can remove that and
% hard-code a column break into the bbl file right before you
% submit:
%
% http://stackoverflow.com/questions/2149854/how-to-manually-equalize-columns-
% in-an-ieee-paper-if-using-bibtex
%
% Or, just remove \balance and give up on balancing the last page.
%
% \balance{}


% BALANCE COLUMNS
\balance{}

% REFERENCES FORMAT
% References must be the same font size as other body text.
\bibliographystyle{SIGCHI-Reference-Format}
\bibliography{references}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
